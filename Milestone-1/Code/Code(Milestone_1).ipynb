{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **TextMorph Advanced Text Summarization and Paraphrasing**\n",
        "Summarization is the process of reducing a long piece of text into a concise version while retaining its main ideas. It is widely used in areas such as research, business reports, and news articles to help readers quickly grasp the essential information without going through the entire content.\n",
        "\n",
        "Paraphrasing involves re-expressing text in a new way while preserving its original meaning. It is important for improving readability, avoiding plagiarism, adapting content for different audiences, and presenting ideas in clearer or more creative forms.\n",
        "\n",
        "This project, TextMorph, focuses on building an advanced system for text summarization and paraphrasing using state-of-the-art models like T5 and PEGASUS. The goal is to make text processing more effective, time-saving, and context-aware, providing high-quality summaries and paraphrases across technical, business, and creative domains."
      ],
      "metadata": {
        "id": "gtoWYgvr5Oq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part-A\n",
        "### Section 1.0: Session Setup\n",
        "Let's get our environment ready by installing and importing the necessary libraries."
      ],
      "metadata": {
        "id": "oc00FxNZq7vO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-wvox98qyKD"
      },
      "outputs": [],
      "source": [
        "#@title 1.0: Install and Import Libraries\n",
        "# Install the required libraries quietly.\n",
        "!pip install transformers sentencepiece --quiet\n",
        "print(\"Libraries are installed.\")\n",
        "\n",
        "# Import the necessary classes from the transformers library.\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "# 'textwrap' is a great tool for formatting our output nicely.\n",
        "import textwrap\n",
        "print(\"Libraries are imported successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 1.1: Loading Our T5 Summarization Model\n",
        "We'll use t5-base, a powerful and well-balanced version of Google's T5 model. It's a great starting point for high-quality summarization."
      ],
      "metadata": {
        "id": "cJIHwvebrP99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.1: Load the T5 Model and Tokenizer\n",
        "# The model name we'll be using.\n",
        "t5_model_name = 't5-base'\n",
        "\n",
        "# The Tokenizer is responsible for converting text into a format the model understands.\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained(t5_model_name)\n",
        "\n",
        "# The Model is the pre-trained AI that performs the summarization.\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained(t5_model_name)\n",
        "\n",
        "print(f\"T5 Model ('{t5_model_name}') is loaded and ready!\")"
      ],
      "metadata": {
        "id": "X4dvu3oLrbPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 1.2: The Summarizer Function\n",
        "This is our core function. We're adding a new parameter, no_repeat_ngram_size, to prevent the model from repeating the same phrases."
      ],
      "metadata": {
        "id": "RY0-wYwurl3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.2: Define the Core Summarizer Function\n",
        "def generate_summary(text, min_len=40, max_len=120, beams=4):\n",
        "    \"\"\"\n",
        "    Generates a high-quality abstractive summary for a given text using the T5 model.\n",
        "    \"\"\"\n",
        "    # T5 models require a \"summarize: \" prefix to know which task to perform.\n",
        "    input_text = \"summarize: \" + text.strip().replace(\"\\n\", \" \")\n",
        "\n",
        "    # Tokenize the text, ensuring it's not too long for the model.\n",
        "    inputs = t5_tokenizer.encode(input_text, return_tensors='pt', max_length=1024, truncation=True)\n",
        "\n",
        "    # Generate the summary using our specified parameters.\n",
        "    summary_ids = t5_model.generate(\n",
        "        inputs,\n",
        "        max_length=max_len,\n",
        "        min_length=min_len,\n",
        "        num_beams=beams,\n",
        "        no_repeat_ngram_size=3, # Prevents repeating phrases of 3 words.\n",
        "        length_penalty=2.0,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Decode the result back into human-readable text.\n",
        "    summary = t5_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary"
      ],
      "metadata": {
        "id": "YBHP7QMDroLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 1.3: Code Examples with Diverse Texts\n",
        "Let's test our summarizer on different styles of writing to see how it performs."
      ],
      "metadata": {
        "id": "7TIIS-hCrrJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.3.1: Example 1 - Technical Text (Deep Learning)\n",
        "technical_text = \"\"\"\n",
        "Deep learning is a subfield of machine learning that focuses on using artificial neural networks with multiple layers to automatically learn complex patterns from large datasets.\n",
        "Unlike traditional machine learning methods, which often rely on handcrafted features, deep learning models can perform automatic feature extraction through hierarchical representations.\n",
        "The most common deep learning architectures include Convolutional Neural Networks (CNNs), which are highly effective for image processing; Recurrent Neural Networks (RNNs) and\n",
        "their variants such as Long Short-Term Memory (LSTM) networks, which are widely used for sequential data like natural language and speech; and Transformers, which have become\n",
        "the state-of-the-art in natural language processing due to their self-attention mechanism. Training deep networks requires large amounts of labeled data, powerful computational\n",
        "resources such as GPUs or TPUs, and optimization techniques like stochastic gradient descent with backpropagation. Despite challenges like overfitting, high computational cost, and\n",
        "lack of interpretability, deep learning has revolutionized domains such as computer vision, speech recognition, natural language processing, and autonomous systems.\n",
        "\"\"\"\n",
        "\n",
        "summary = generate_summary(technical_text, min_len=50, max_len=100)\n",
        "\n",
        "print(\"----------- TECHNICAL TEXT -----------\")\n",
        "print(textwrap.fill(technical_text, width=100))\n",
        "print(\"\\n---------- T5 SUMMARY -----------\")\n",
        "print(textwrap.fill(summary, width=100))"
      ],
      "metadata": {
        "id": "dlY39-otrsL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.3.2: Example 2 - Business Text (Small Businesses)\n",
        "business_text = \"\"\"\n",
        "Small businesses play a vital role in the economy by generating employment, fostering innovation, and contributing to local communities.\n",
        "They are typically privately owned enterprises with fewer employees and lower revenue compared to large corporations. Access to funding\n",
        "remains one of the biggest challenges for small businesses, as they often rely on personal savings, bank loans, or government schemes.\n",
        "The adoption of digital technologies, such as e-commerce platforms, cloud services, and digital marketing tools, has significantly improved\n",
        "their ability to compete with larger firms. However, small businesses also face obstacles like regulatory compliance, limited scalability,\n",
        "and vulnerability to market fluctuations. With effective financial management, customer relationship strategies, and innovation, small\n",
        "businesses can sustain growth and create long-term economic impact.\n",
        "\"\"\"\n",
        "\n",
        "summary = generate_summary(business_text, min_len=50, max_len=90)\n",
        "\n",
        "print(\"----------- BUSINESS TEXT -----------\")\n",
        "print(textwrap.fill(business_text, width=100))\n",
        "print(\"\\n---------- T5 SUMMARY -----------\")\n",
        "print(textwrap.fill(summary, width=100))"
      ],
      "metadata": {
        "id": "cP1O3t4Mr0k7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.3.3: Example 3 - Creative Text (Hidden Worlds)\n",
        "creative_text = \"\"\"\n",
        "The little bookstore at the corner of the street seemed almost invisible to the rushing crowd, yet inside it\n",
        "carried worlds beyond imagination. Dusty shelves leaned under the weight of forgotten tales, while sunlight\n",
        "fell like golden ribbons across the cracked wooden floor. Each book whispered promises of faraway lands,\n",
        "adventures yet to be lived, and memories waiting to be revived. For the few who wandered in, time slowed,\n",
        "and the noise of the city melted into silence, replaced by the quiet hum of stories eager to be discovered.\n",
        "\"\"\"\n",
        "\n",
        "summary = generate_summary(creative_text, min_len=30, max_len=50)\n",
        "\n",
        "print(\"----------- CREATIVE TEXT -----------\")\n",
        "print(textwrap.fill(creative_text, width=100))\n",
        "print(\"\\n---------- T5 SUMMARY -----------\")\n",
        "print(textwrap.fill(summary, width=100))"
      ],
      "metadata": {
        "id": "bA8SZFWHr1z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 1.4: The Interactive Summarizer Studio\n",
        "Now it's your turn! Paste your own text, experiment with the settings, and see how you can craft the perfect summary."
      ],
      "metadata": {
        "id": "hk9L0LrpsAis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.4: Your Interactive Summarizer Studio!\n",
        "#@markdown ### Paste your text below and tune the parameters!\n",
        "input_text = \"'Planets are celestial bodies that orbit stars and do not produce their own light. In our solar system, there are eight recognized planets divided into two groups: terrestrial planets and gas giants. The terrestrial planets—Mercury, Venus, Earth, and Mars—are small, rocky, and have solid surfaces. Gas giants, which include Jupiter and Saturn, along with ice giants Uranus and Neptune, are massive planets composed mostly of hydrogen, helium, and other gases. Each planet has unique features, such as Earth’s ability to support life, Jupiter’s Great Red Spot, or Saturn’s rings. Studying planets helps scientists understand the formation of solar systems, the possibility of extraterrestrial life, and the conditions necessary for habitability.'\" #@param {type:\"string\"}\n",
        "min_length = 30 #@param {type:\"slider\", min:10, max:100, step:5}\n",
        "max_length = 80 #@param {type:\"slider\", min:50, max:200, step:10}\n",
        "num_beams = 4 #@param {type:\"slider\", min:2, max:8, step:1}\n",
        "\n",
        "# --- Run the summarizer with your settings ---\n",
        "generated_summary = generate_summary(input_text, min_len=min_length, max_len=max_length, beams=num_beams)\n",
        "\n",
        "# --- Display the results and analysis ---\n",
        "original_word_count = len(input_text.split())\n",
        "summary_word_count = len(generated_summary.split())\n",
        "reduction = 100 - (summary_word_count / original_word_count * 100)\n",
        "\n",
        "print(\"----------- YOUR INPUT TEXT -----------\")\n",
        "print(textwrap.fill(input_text, width=100))\n",
        "print(\"\\n---------- GENERATED SUMMARY -----------\")\n",
        "print(textwrap.fill(generated_summary, width=100))\n",
        "print(\"\\n---------- ANALYSIS -----------\")\n",
        "print(f\"Original Word Count: {original_word_count}\")\n",
        "print(f\"Summary Word Count: {summary_word_count}\")\n",
        "print(f\"Text Reduction: {reduction:.1f}%\")"
      ],
      "metadata": {
        "id": "tYi2rfyHsB8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2.0: Loading Our PEGASUS Paraphrasing Model\n",
        "We'll use a PEGASUS model that has been specifically fine-tuned for the task of paraphrasing."
      ],
      "metadata": {
        "id": "AO_iulbssufr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.0: Load the PEGASUS Model and Tokenizer\n",
        "paraphrase_model_name = 'tuner007/pegasus_paraphrase'\n",
        "\n",
        "pegasus_tokenizer = PegasusTokenizer.from_pretrained(paraphrase_model_name)\n",
        "pegasus_model = PegasusForConditionalGeneration.from_pretrained(paraphrase_model_name)\n",
        "\n",
        "print(f\"PEGASUS Model ('{paraphrase_model_name}') is loaded and ready!\")"
      ],
      "metadata": {
        "id": "FHx807OAswKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2.1: The Paraphraser Function\n",
        "This function will take our input sentence and generate a list of high-quality alternatives.\n",
        "\n"
      ],
      "metadata": {
        "id": "44GIzYCotHVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.1: Define the Core Paraphraser Function\n",
        "def generate_paraphrases(text, num_return=5, beams=10):\n",
        "    \"\"\"\n",
        "    Generates multiple high-quality paraphrases for a given text using the PEGASUS model.\n",
        "    \"\"\"\n",
        "    # Tokenize the input text.\n",
        "    inputs = pegasus_tokenizer.encode(text, return_tensors='pt', truncation=True)\n",
        "\n",
        "    # Generate the paraphrases using beam search.\n",
        "    paraphrase_ids = pegasus_model.generate(\n",
        "        inputs,\n",
        "        max_length=60,\n",
        "        num_beams=beams,\n",
        "        num_return_sequences=num_return,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Decode the results back into text.\n",
        "    paraphrases = pegasus_tokenizer.batch_decode(paraphrase_ids, skip_special_tokens=True)\n",
        "    return paraphrases"
      ],
      "metadata": {
        "id": "aOrP0UGAtIz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2.2: Code Examples with Diverse Sentences\n",
        "Let's see how PEGASUS handles different kinds of language."
      ],
      "metadata": {
        "id": "F3NCR6HFtZAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.2.1: Example 1 - Formal / Academic Sentence\n",
        "formal_sentence = \"Artificial intelligence is transforming various industries by enabling automation and data-driven decision-making. Its integration into healthcare, finance, and education has improved efficiency and accuracy.\"\n",
        "paraphrases = generate_paraphrases(formal_sentence, num_return=3)\n",
        "\n",
        "print(f\"----------- ORIGINAL FORMAL SENTENCE -----------\\n'{formal_sentence}'\\n\")\n",
        "print(\"---------- PEGASUS PARAPHRASES ----------\")\n",
        "for i, p in enumerate(paraphrases):\n",
        "    print(f\"  {i+1}. {p}\")"
      ],
      "metadata": {
        "id": "zf5GrvdktaX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.2.2: Example 2 - Casual / Idiomatic Sentence\n",
        "casual_sentence = \"Sara was on cloud nine after hearing she won the competition.\"\n",
        "paraphrases = generate_paraphrases(casual_sentence, num_return=4)\n",
        "\n",
        "print(f\"----------- ORIGINAL CASUAL SENTENCE -----------\\n'{casual_sentence}'\\n\")\n",
        "print(\"---------- PEGASUS PARAPHRASES ----------\")\n",
        "for i, p in enumerate(paraphrases):\n",
        "    print(f\"  {i+1}. {p}\")"
      ],
      "metadata": {
        "id": "VIyYbuHfti7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.2.3: Example 3 - Marketing Call-to-Action\n",
        "marketing_sentence = \"Sign up today and get exclusive access to our latest deals before anyone else!\"\n",
        "paraphrases = generate_paraphrases(marketing_sentence, num_return=4)\n",
        "\n",
        "print(f\"----------- ORIGINAL MARKETING SENTENCE -----------\\n'{marketing_sentence}'\\n\")\n",
        "print(\"---------- PEGASUS PARAPHRASES ----------\")\n",
        "for i, p in enumerate(paraphrases):\n",
        "    print(f\"  {i+1}. {p}\")"
      ],
      "metadata": {
        "id": "3klrMh-gtqS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2.3: The Interactive Paraphraser Playground\n",
        "Your turn! Enter any sentence and generate creative new ways to phrase it."
      ],
      "metadata": {
        "id": "Wi1ZSh1ntwng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.3: Your Interactive Paraphraser Playground!\n",
        "#@markdown ###  Type your sentence and choose your settings!\n",
        "input_sentence = \"Discover the benefits of adopting a healthy lifestyle today.\" #@param {type:\"string\"}\n",
        "num_paraphrases = 6 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "quality_vs_speed_beams = 6 #@param {type:\"slider\", min:2, max:15, step:1}\n",
        "\n",
        "# --- Run the paraphraser with your settings ---\n",
        "generated_paraphrases = generate_paraphrases(input_sentence, num_return=num_paraphrases, beams=quality_vs_speed_beams)\n",
        "\n",
        "# --- Display the results ---\n",
        "print(f\"----------- ORIGINAL SENTENCE -----------\\n'{input_sentence}'\\n\")\n",
        "print(f\"---------- {len(generated_paraphrases)} GENERATED PARAPHRASES (Quality: {quality_vs_speed_beams}) ----------\")\n",
        "for i, p in enumerate(generated_paraphrases):\n",
        "    print(f\"  {i+1}. {p}\")"
      ],
      "metadata": {
        "id": "zNNmDBpQtx78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part-B\n",
        "### Section 0.1: Install Libraries\n",
        "Install required dependencies (no NLTK, spaCy, langdetect, textstat, or wordcloud)."
      ],
      "metadata": {
        "id": "otGaT0FPiBgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentencepiece sentence-transformers scikit-learn matplotlib pandas --quiet\n",
        "print(\"Libraries are installed.\")"
      ],
      "metadata": {
        "id": "K7r_cf92iGjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 0.2: Import Libraries\n",
        "Import necessary libraries."
      ],
      "metadata": {
        "id": "gq6OY1XmiJZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import textwrap\n",
        "import re\n",
        "import requests\n",
        "import ssl\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Handle SSL for file downloads\n",
        "try:\n",
        "    _create_unverified_https_context = ssl._create_unverified_context\n",
        "except AttributeError:\n",
        "    pass\n",
        "else:\n",
        "    ssl._create_default_https_context = _create_unverified_https_context\n",
        "\n",
        "print(\"Libraries are imported.\")"
      ],
      "metadata": {
        "id": "J5hNxBVkiSX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 0.3: Load Summarization Models\n",
        "Load T5, BART, and PEGASUS for summarization."
      ],
      "metadata": {
        "id": "h75sUp1kiuX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t5_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
        "bart_model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
        "pegasus_sum_tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-xsum')\n",
        "pegasus_sum_model = PegasusForConditionalGeneration.from_pretrained('google/pegasus-xsum')\n",
        "print(\"Summarization models loaded: T5, BART, PEGASUS.\")"
      ],
      "metadata": {
        "id": "buI7EoqrivUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 0.4: Load Paraphrasing Models\n",
        "Load PEGASUS, T5-Paraphrase, and BART-Paraphrase."
      ],
      "metadata": {
        "id": "Q3eO-zfdi25k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pegasus_para_tokenizer = PegasusTokenizer.from_pretrained('tuner007/pegasus_paraphrase')\n",
        "pegasus_para_model = PegasusForConditionalGeneration.from_pretrained('tuner007/pegasus_paraphrase')\n",
        "paraphrase_t5_tokenizer = T5Tokenizer.from_pretrained('Vamsi/T5_Paraphrase_Paws')\n",
        "paraphrase_t5_model = T5ForConditionalGeneration.from_pretrained('Vamsi/T5_Paraphrase_Paws')\n",
        "paraphrase_bart_tokenizer = BartTokenizer.from_pretrained('eugenesiow/bart-paraphrase')\n",
        "paraphrase_bart_model = BartForConditionalGeneration.from_pretrained('eugenesiow/bart-paraphrase')\n",
        "print(\"Paraphrasing models loaded: PEGASUS, T5-Paraphrase, BART-Paraphrase.\")"
      ],
      "metadata": {
        "id": "r1w6DcObi35l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 0.5: Load Similarity Model\n",
        "Load SentenceTransformer for similarity."
      ],
      "metadata": {
        "id": "sSI553Cui9pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"Similarity model loaded.\")"
      ],
      "metadata": {
        "id": "rK5pQrF8i-dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Text Input Processing\n",
        "### Section 1.1: Load Single Text File\n",
        "Load and clean a text file from a URL, with a fallback if the request fails."
      ],
      "metadata": {
        "id": "EMGnDj2OjAxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_text_file(url):\n",
        "    \"\"\"Load and clean text from a URL.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=30)\n",
        "        response.raise_for_status()\n",
        "        text = response.text\n",
        "        # Clean Gutenberg headers/footers\n",
        "        start_idx = max([text.find(marker) for marker in [\"*** START OF\", \"CHAPTER\"]] + [0])\n",
        "        end_idx = text.find(\"*** END OF\")\n",
        "        if start_idx > 0 and end_idx > 0:\n",
        "            text = text[start_idx:end_idx]\n",
        "        if len(text) < 100:\n",
        "            raise ValueError(\"Text is too short.\")\n",
        "        return text.strip(), \"Text file\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading text from {url}: {e}\")\n",
        "        fallback = \"\"\"Natural Language Processing enables computers to understand human language.\"\"\"\n",
        "        return fallback, \"Fallback text\""
      ],
      "metadata": {
        "id": "LWigWKhFjFAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 1.2: Validate Text Input\n",
        "Validate text length and content, ensure the loaded text is sufficiently long and is a string."
      ],
      "metadata": {
        "id": "iJ3hz-DFjJiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_text(text):\n",
        "    \"\"\"Validate text input.\"\"\"\n",
        "    if not isinstance(text, str) or len(text.strip()) < 50:\n",
        "        raise ValueError(\"Invalid text: must be a string with at least 50 characters.\")\n",
        "    return text"
      ],
      "metadata": {
        "id": "V-Arv89mjM5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 1.3: Load Multiple Text Files\n",
        "Load two text files for processing, limiting to 50,000 characters each."
      ],
      "metadata": {
        "id": "U9lJUUltjPQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_multiple_text_files(urls):\n",
        "    \"\"\"Load multiple text files with validation.\"\"\"\n",
        "    if len(urls) != 2:\n",
        "        raise ValueError(\"Exactly two URLs must be provided.\")\n",
        "    texts = {}\n",
        "    for i, url in enumerate(urls, 1):\n",
        "        text, source = load_text_file(url)\n",
        "        text = validate_text(text)\n",
        "        texts[f\"Text {i}\"] = {'text': text[:50000], 'source': source}  # Limit size\n",
        "    return texts"
      ],
      "metadata": {
        "id": "ID481QGZjSsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 1.4: Test Text Loading\n",
        "Load and preview two example Gutenberg texts."
      ],
      "metadata": {
        "id": "gjtIBn2JjX3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_urls = [\n",
        "    \"https://www.gutenberg.org/files/11/11-0.txt\",  # Alice's Adventures in Wonderland\n",
        "    \"https://www.gutenberg.org/files/1661/1661-0.txt\"  # The Adventures of Sherlock Holmes\n",
        "]\n",
        "loaded_texts = load_multiple_text_files(file_urls)\n",
        "    # Clean all loaded texts and show structured preview\n",
        "for key, data in loaded_texts.items():\n",
        "    loaded_texts[key]['text'] = clean_text(data['text'])\n",
        "    print(f\"\\n{key} ({data['source']}): {len(loaded_texts[key]['text']):,} characters\")\n",
        "    # Take first 500 chars for preview\n",
        "    preview_text = loaded_texts[key]['text'][:500]\n",
        "\n",
        "    # Replace common section delimiters with newline for readability\n",
        "    preview_text = re.sub(r'CHAPTER\\s+\\w+\\.?', r'\\n\\g<0>', preview_text, flags=re.IGNORECASE)\n",
        "    preview_text = re.sub(r'I\\.', r'\\nI.', preview_text)\n",
        "    preview_text = re.sub(r'II\\.', r'\\nII.', preview_text)\n",
        "    preview_text = re.sub(r'III\\.', r'\\nIII.', preview_text)\n",
        "    preview_text = re.sub(r'IV\\.', r'\\nIV.', preview_text)\n",
        "    preview_text = re.sub(r'V\\.', r'\\nV.', preview_text)\n",
        "\n",
        "    print(f\"Preview:\\n{preview_text}\\n\")\n"
      ],
      "metadata": {
        "id": "DFcGylwIjY9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Core Analysis Components\n",
        "### Section 2.1: T5 Summarization\n",
        "Summarize text using T5."
      ],
      "metadata": {
        "id": "brJXyI6yjbtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_t5_summary(text, min_len=40, max_len=150, beams=4):\n",
        "    \"\"\"Abstractive summarization with T5.\"\"\"\n",
        "    input_text = \"summarize: \" + text.strip().replace(\"\\n\", \" \")\n",
        "    inputs = t5_tokenizer.encode(input_text, return_tensors='pt', max_length=1024, truncation=True)\n",
        "    summary_ids = t5_model.generate(\n",
        "        inputs,\n",
        "        max_length=max_len,\n",
        "        min_length=min_len,\n",
        "        num_beams=beams,\n",
        "        no_repeat_ngram_size=3,\n",
        "        length_penalty=2.0,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    return t5_tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "T6xztHMzjeoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"Remove non-ASCII characters, Gutenberg headers/footers, and normalize whitespace.\"\"\"\n",
        "    # Remove Gutenberg headers/footers\n",
        "    text = re.sub(r'\\*\\*\\*.*?START OF.*?\\*\\*\\*', '', text, flags=re.DOTALL)\n",
        "    text = re.sub(r'\\*\\*\\*.*?END OF.*?\\*\\*\\*', '', text, flags=re.DOTALL)\n",
        "    # Remove non-ASCII characters\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
        "    # Normalize whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n"
      ],
      "metadata": {
        "id": "dIdrPbQmoxLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2.2: BART Summarization\n",
        "Summarize text using BART."
      ],
      "metadata": {
        "id": "lvAjCpv_jku1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_bart_summary(text, min_len=40, max_len=150, beams=4):\n",
        "    \"\"\"Abstractive summarization with BART.\"\"\"\n",
        "    inputs = bart_tokenizer.encode(text, return_tensors='pt', max_length=1024, truncation=True)\n",
        "    summary_ids = bart_model.generate(\n",
        "        inputs,\n",
        "        max_length=max_len,\n",
        "        min_length=min_len,\n",
        "        num_beams=beams,\n",
        "        no_repeat_ngram_size=3,\n",
        "        length_penalty=2.0,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    return bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "jXnJC-wNjl1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2.3: PEGASUS Summarization\n",
        "Summarize text using PEGASUS."
      ],
      "metadata": {
        "id": "lUL-BMTojpDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_pegasus_summary(text, min_len=40, max_len=150, beams=4):\n",
        "    \"\"\"Abstractive summarization with PEGASUS.\"\"\"\n",
        "    # Clean and truncate input to prevent tokenization issues\n",
        "    text = clean_text(text[:1500])  # Stricter truncation to 1500 chars\n",
        "    try:\n",
        "        inputs = pegasus_sum_tokenizer.encode(\n",
        "            text,\n",
        "            return_tensors='pt',\n",
        "            max_length=512,  # Reduced max_length for safety\n",
        "            truncation=True,\n",
        "            padding='max_length'  # Ensure consistent input size\n",
        "        )\n",
        "        # Validate token IDs\n",
        "        if inputs.max().item() >= pegasus_sum_tokenizer.vocab_size:\n",
        "            raise ValueError(f\"Token ID {inputs.max().item()} exceeds vocab size {pegasus_sum_tokenizer.vocab_size}.\")\n",
        "        summary_ids = pegasus_sum_model.generate(\n",
        "            inputs,\n",
        "            max_length=max_len,\n",
        "            min_length=min_len,\n",
        "            num_beams=beams,\n",
        "            no_repeat_ngram_size=3,\n",
        "            length_penalty=2.0,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        return pegasus_sum_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    except Exception as e:\n",
        "        print(f\"PEGASUS summarization failed: {e}\")\n",
        "        return \"Summary unavailable due to processing error.\""
      ],
      "metadata": {
        "id": "erKxAroQjul3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2.4: PEGASUS Paraphrasing\n",
        "Generate paraphrases using PEGASUS."
      ],
      "metadata": {
        "id": "IywgPGxfjyCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_pegasus_paraphrase(text, num_return=3, beams=10):\n",
        "    \"\"\"Generate paraphrases with PEGASUS.\"\"\"\n",
        "    inputs = pegasus_para_tokenizer.encode(text, return_tensors='pt', truncation=True, max_length=60)\n",
        "    paraphrase_ids = pegasus_para_model.generate(\n",
        "        inputs,\n",
        "        max_length=60,\n",
        "        num_beams=beams,\n",
        "        num_return_sequences=num_return,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    return pegasus_para_tokenizer.batch_decode(paraphrase_ids, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "VEXAsUhWj0K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2.5: T5 Paraphrasing\n",
        "Generate paraphrases using T5-Paraphrase."
      ],
      "metadata": {
        "id": "OaZP2Yudj6TK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_t5_paraphrase(text, num_return=3, beams=10):\n",
        "    \"\"\"Generate paraphrases with T5-Paraphrase.\"\"\"\n",
        "    input_text = f\"paraphrase: {text} </s>\"\n",
        "    inputs = paraphrase_t5_tokenizer.encode(input_text, return_tensors='pt', max_length=512, truncation=True)\n",
        "    paraphrase_ids = paraphrase_t5_model.generate(\n",
        "        inputs,\n",
        "        max_length=60,\n",
        "        num_beams=beams,\n",
        "        num_return_sequences=num_return,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    return paraphrase_t5_tokenizer.batch_decode(paraphrase_ids, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "uqN4KPlxj7Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2.6: BART Paraphrasing\n",
        "Generate paraphrases using BART-Paraphrase."
      ],
      "metadata": {
        "id": "hyvg3h5qkBnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_bart_paraphrase(text, num_return=3, beams=10):\n",
        "    \"\"\"Generate paraphrases with BART-Paraphrase.\"\"\"\n",
        "    inputs = paraphrase_bart_tokenizer.encode(text, return_tensors='pt', truncation=True, max_length=60)\n",
        "    paraphrase_ids = paraphrase_bart_model.generate(\n",
        "        inputs,\n",
        "        max_length=60,\n",
        "        num_beams=beams,\n",
        "        num_return_sequences=num_return,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    return paraphrase_bart_tokenizer.batch_decode(paraphrase_ids, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "wuYhp9q2kCcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2.7: Similarity Analysis\n",
        "Compute semantic similarity."
      ],
      "metadata": {
        "id": "b0O2Qs3DkHD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_similarity(text1, text2):\n",
        "    \"\"\"Compute cosine similarity between texts safely.\"\"\"\n",
        "    if not text1.strip() or not text2.strip():\n",
        "        return 0.0\n",
        "    embeddings = similarity_model.encode([text1, text2])\n",
        "    return cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]"
      ],
      "metadata": {
        "id": "DcH5JhqhkHu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Enhanced Model Comparison\n",
        "### Section 3.1: Summary Length Analysis\n",
        "Compute summary length."
      ],
      "metadata": {
        "id": "jVwBdE9tkLDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_summary_length(summary):\n",
        "    \"\"\"Compute word count of summary.\"\"\"\n",
        "    return len(summary.split())  # Simple split instead of NLTK tokenization"
      ],
      "metadata": {
        "id": "tI6FLsq0kNWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 3.2: Similarity to Original\n",
        "Compute similarity to original text."
      ],
      "metadata": {
        "id": "56u6ccYWkSQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity_to_original(summary, original_text):\n",
        "    \"\"\"Compute similarity between summary and original.\"\"\"\n",
        "    return compute_similarity(summary, original_text[:2000])"
      ],
      "metadata": {
        "id": "iWR2WO3YkUfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 3.3: Enhanced Summarization Comparison\n",
        "Compare T5, BART, and PEGASUS for summarization."
      ],
      "metadata": {
        "id": "ytOszqKGkYPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_summarizers_enhanced(text, min_len=40, max_len=150, beams=4):\n",
        "    \"\"\"Enhanced comparison of T5, BART, and PEGASUS for summarization.\"\"\"\n",
        "    t5_sum = generate_t5_summary(text[:2000], min_len, max_len, beams)\n",
        "    bart_sum = generate_bart_summary(text[:2000], min_len, max_len, beams)\n",
        "    pegasus_sum = generate_pegasus_summary(text[:2000], min_len, max_len, beams)\n",
        "\n",
        "    metrics = {\n",
        "        't5': {\n",
        "            'summary': t5_sum,\n",
        "            'length': analyze_summary_length(t5_sum),\n",
        "            'sim_to_original': similarity_to_original(t5_sum, text)\n",
        "        },\n",
        "        'bart': {\n",
        "            'summary': bart_sum,\n",
        "            'length': analyze_summary_length(bart_sum),\n",
        "            'sim_to_original': similarity_to_original(bart_sum, text)\n",
        "        },\n",
        "        'pegasus': {\n",
        "            'summary': pegasus_sum,\n",
        "            'length': analyze_summary_length(pegasus_sum),\n",
        "            'sim_to_original': similarity_to_original(pegasus_sum, text)\n",
        "        },\n",
        "        'sim_t5_bart': compute_similarity(t5_sum, bart_sum),\n",
        "        'sim_t5_pegasus': compute_similarity(t5_sum, pegasus_sum),\n",
        "        'sim_bart_pegasus': compute_similarity(bart_sum, pegasus_sum)\n",
        "    }\n",
        "\n",
        "    print(\"----------- Enhanced Summarization Comparison -----------\")\n",
        "    print(f\"T5 Summary (Length: {metrics['t5']['length']}, Sim to Original: {metrics['t5']['sim_to_original']:.3f}):\")\n",
        "    print(textwrap.fill(t5_sum, width=100))\n",
        "    print(f\"\\nBART Summary (Length: {metrics['bart']['length']}, Sim to Original: {metrics['bart']['sim_to_original']:.3f}):\")\n",
        "    print(textwrap.fill(bart_sum, width=100))\n",
        "    print(f\"\\nPEGASUS Summary (Length: {metrics['pegasus']['length']}, Sim to Original: {metrics['pegasus']['sim_to_original']:.3f}):\")\n",
        "    print(textwrap.fill(pegasus_sum, width=100))\n",
        "    print(f\"\\nSimilarity T5 vs BART: {metrics['sim_t5_bart']:.3f}\")\n",
        "    print(f\"Similarity T5 vs PEGASUS: {metrics['sim_t5_pegasus']:.3f}\")\n",
        "    print(f\"Similarity BART vs PEGASUS: {metrics['sim_bart_pegasus']:.3f}\")\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "2mErKEJEkZEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 3.4: Enhanced Paraphrasing Comparison\n",
        "Compare PEGASUS, T5-Paraphrase, and BART-Paraphrase."
      ],
      "metadata": {
        "id": "aZOLpEnqkjyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_paraphrasers_enhanced(text, num_return=3, beams=10):\n",
        "    \"\"\"Enhanced comparison of PEGASUS, T5-Paraphrase, and BART-Paraphrase.\"\"\"\n",
        "    peg_paras = generate_pegasus_paraphrase(text, num_return, beams)\n",
        "    t5_paras = generate_t5_paraphrase(text, num_return, beams)\n",
        "    bart_paras = generate_bart_paraphrase(text, num_return, beams)\n",
        "\n",
        "    metrics = {\n",
        "        'pegasus': {\n",
        "            'paraphrases': peg_paras,\n",
        "            'avg_length': sum(len(p.split()) for p in peg_paras) / len(peg_paras),\n",
        "            'avg_sim_to_original': sum(compute_similarity(p, text) for p in peg_paras) / len(peg_paras)\n",
        "        },\n",
        "        't5_paraphrase': {\n",
        "            'paraphrases': t5_paras,\n",
        "            'avg_length': sum(len(p.split()) for p in t5_paras) / len(t5_paras),\n",
        "            'avg_sim_to_original': sum(compute_similarity(p, text) for p in t5_paras) / len(t5_paras)\n",
        "        },\n",
        "        'bart_paraphrase': {\n",
        "            'paraphrases': bart_paras,\n",
        "            'avg_length': sum(len(p.split()) for p in bart_paras) / len(bart_paras),\n",
        "            'avg_sim_to_original': sum(compute_similarity(p, text) for p in bart_paras) / len(bart_paras)\n",
        "        },\n",
        "        'avg_sim_peg_t5': sum(compute_similarity(peg_paras[i], t5_paras[i]) for i in range(num_return)) / num_return,\n",
        "        'avg_sim_peg_bart': sum(compute_similarity(peg_paras[i], bart_paras[i]) for i in range(num_return)) / num_return,\n",
        "        'avg_sim_t5_bart': sum(compute_similarity(t5_paras[i], bart_paras[i]) for i in range(num_return)) / num_return\n",
        "    }\n",
        "\n",
        "    print(\"----------- Enhanced Paraphrasing Comparison -----------\")\n",
        "    print(f\"PEGASUS Paraphrases (Avg Length: {metrics['pegasus']['avg_length']:.1f}, Avg Sim to Original: {metrics['pegasus']['avg_sim_to_original']:.3f}):\")\n",
        "    for i, p in enumerate(peg_paras, 1):\n",
        "        print(f\"  {i}. {p}\")\n",
        "    print(f\"\\nT5-Paraphrase Paraphrases (Avg Length: {metrics['t5_paraphrase']['avg_length']:.1f}, Avg Sim to Original: {metrics['t5_paraphrase']['avg_sim_to_original']:.3f}):\")\n",
        "    for i, p in enumerate(t5_paras, 1):\n",
        "        print(f\"  {i}. {p}\")\n",
        "    print(f\"\\nBART-Paraphrase Paraphrases (Avg Length: {metrics['bart_paraphrase']['avg_length']:.1f}, Avg Sim to Original: {metrics['bart_paraphrase']['avg_sim_to_original']:.3f}):\")\n",
        "    for i, p in enumerate(bart_paras, 1):\n",
        "        print(f\"  {i}. {p}\")\n",
        "    print(f\"\\nAverage Similarity PEGASUS vs T5-Paraphrase: {metrics['avg_sim_peg_t5']:.3f}\")\n",
        "    print(f\"Average Similarity PEGASUS vs BART-Paraphrase: {metrics['avg_sim_peg_bart']:.3f}\")\n",
        "    print(f\"Average Similarity T5-Paraphrase vs BART-Paraphrase: {metrics['avg_sim_t5_bart']:.3f}\")\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "5tCRtDqjkmol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Integrated TextMorph Pipeline\n",
        "### Section 4.1: Pipeline Initialization\n",
        "Initialize the pipeline class."
      ],
      "metadata": {
        "id": "TALNNGd4kvyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextMorphPipeline:\n",
        "    \"\"\"Streamlined TextMorph pipeline for text files, no preprocessing or NLP.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reference_texts = []\n",
        "\n",
        "    def add_reference(self, text):\n",
        "        \"\"\"Add reference text for similarity.\"\"\"\n",
        "        self.reference_texts.append(text)"
      ],
      "metadata": {
        "id": "0NOx3wfykyVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 4.2: Pipeline Summarization Step\n",
        "Summarize in pipeline."
      ],
      "metadata": {
        "id": "Fv1uzKPKk1Ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline_summarize(self, input_text, summarizer='t5'):\n",
        "    \"\"\"Summarization step in pipeline.\"\"\"\n",
        "    if summarizer == 't5':\n",
        "        summary = generate_t5_summary(input_text)\n",
        "    elif summarizer == 'bart':\n",
        "        summary = generate_bart_summary(input_text)\n",
        "    elif summarizer == 'pegasus':\n",
        "        summary = generate_pegasus_summary(input_text)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid summarizer. Choose 't5', 'bart', or 'pegasus'.\")\n",
        "    return summary, summarizer"
      ],
      "metadata": {
        "id": "fZbY02Qdk8RR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 4.3: Pipeline Paraphrasing Step\n",
        "Paraphrase in pipeline with comparison."
      ],
      "metadata": {
        "id": "_cRwE7jQk_TD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline_paraphrase(self, input_text, paraphrase_sentences=2):\n",
        "    \"\"\"Paraphrasing step with comparison, robust version.\"\"\"\n",
        "    # Split into sentences and filter out very short ones\n",
        "    sentences = [s.strip() for s in re.split(r'[.!?]+', input_text) if len(s.strip()) > 20]\n",
        "    if not sentences:\n",
        "        # Fallback if no sentence is long enough\n",
        "        sentences = [input_text[:100].strip()]\n",
        "    sentences = sentences[:paraphrase_sentences]  # limit to requested number\n",
        "\n",
        "    paraphrases = {}\n",
        "    for i, sent in enumerate(sentences):\n",
        "        key = f'Sentence {i+1}'\n",
        "        metrics = compare_paraphrasers_enhanced(sent)\n",
        "        paraphrases[key] = {'original': sent[:100] + \"...\", 'metrics': metrics}\n",
        "    return paraphrases\n"
      ],
      "metadata": {
        "id": "qAf8trqElB0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 4.4: Pipeline Similarity Step\n",
        "Compute similarity in pipeline."
      ],
      "metadata": {
        "id": "V8-y7PHplEQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline_similarity(self, input_text, top_k_similar=2):\n",
        "    \"\"\"Similarity step in pipeline.\"\"\"\n",
        "    if self.reference_texts:\n",
        "        similarities = [(i+1, compute_similarity(input_text[:2000], ref)) for i, ref in enumerate(self.reference_texts)]\n",
        "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "        return similarities[:top_k_similar]\n",
        "    return []"
      ],
      "metadata": {
        "id": "IENpCAPvlGy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 4.5: Full Pipeline Process\n",
        "Run the full pipeline."
      ],
      "metadata": {
        "id": "vAL3-1IklJmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process(self, input_text, summarizer='t5', paraphrase_sentences=2, top_k_similar=2):\n",
        "    \"\"\"Run the full pipeline.\"\"\"\n",
        "    results = {}\n",
        "\n",
        "    summary, used_summarizer = pipeline_summarize(self, input_text, summarizer)\n",
        "    results['summary'] = summary\n",
        "    results['summarizer_used'] = used_summarizer\n",
        "\n",
        "    results['paraphrases'] = pipeline_paraphrase(self, input_text, paraphrase_sentences)\n",
        "\n",
        "    results['similarities'] = pipeline_similarity(self, input_text, top_k_similar)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Bind methods to class\n",
        "TextMorphPipeline.pipeline_summarize = pipeline_summarize\n",
        "TextMorphPipeline.pipeline_paraphrase = pipeline_paraphrase\n",
        "TextMorphPipeline.pipeline_similarity = pipeline_similarity\n",
        "TextMorphPipeline.process = process\n",
        "\n",
        "# Initialize\n",
        "pipeline = TextMorphPipeline()"
      ],
      "metadata": {
        "id": "YhtFAFRBlSza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Testing with Text Files\n",
        "### Section 5.1: Add Reference Texts\n",
        "Add references for similarity.\n",
        "Add reference sentences for similarity/comparison purposes"
      ],
      "metadata": {
        "id": "ZRBPgtRLlV8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.add_reference(\"Natural Language Processing powers modern AI applications.\")\n",
        "pipeline.add_reference(\"Machine learning enhances text analysis capabilities.\")\n",
        "print(\"Reference texts added.\")"
      ],
      "metadata": {
        "id": "zvvsZtKVlXCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 5.2: Process First Text (T5)\n",
        "Run pipeline with T5 summarizer on the first text (Alice’s Adventures in Wonderland)."
      ],
      "metadata": {
        "id": "cIEFjjk8lY_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_text = loaded_texts['Text 1']['text'][:2000]\n",
        "results_t5_first = pipeline.process(first_text, summarizer='t5')\n",
        "print(\"----------- T5 on First Text (Alice’s Adventures in Wonderland) -----------\")\n",
        "print(f\"Summary: {textwrap.fill(results_t5_first['summary'], width=100)}\")"
      ],
      "metadata": {
        "id": "ZEejdf_zlcFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 5.3: Process Second Text (PEGASUS)\n",
        "Run pipeline with PEGASUS on second text (The Adventures of Sherlock Holmes)."
      ],
      "metadata": {
        "id": "GwXLK4uwlf4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "second_text = loaded_texts['Text 2']['text'][:2000]\n",
        "results_pegasus_second = pipeline.process(second_text, summarizer='pegasus')\n",
        "print(\"----------- PEGASUS on Second Text (The Adventures of Sherlock Holmes) -----------\")\n",
        "print(f\"Summary: {textwrap.fill(results_pegasus_second['summary'], width=100)}\")"
      ],
      "metadata": {
        "id": "zvG4By8Slg7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 5.4: Enhanced Comparison on Both Texts\n",
        "Compare T5, BART, and PEGASUS on both texts."
      ],
      "metadata": {
        "id": "pv1-YYqjljmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"----------- Enhanced Summarization Comparison on First Text -----------\")\n",
        "comparison_first = compare_summarizers_enhanced(first_text)\n",
        "print(\"----------- Enhanced Summarization Comparison on Second Text -----------\")\n",
        "comparison_second = compare_summarizers_enhanced(second_text)"
      ],
      "metadata": {
        "id": "N-SzvgGJlmwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6: Visualization & Insights\n",
        "### Section 6.1: Enhanced Summarization Metrics Plot\n",
        "Visualize T5 vs BART vs PEGASUS metrics."
      ],
      "metadata": {
        "id": "76X5XxrdlpU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_enhanced_summarization_comparison(metrics, title=\"Summarization Comparison\"):\n",
        "    \"\"\"Plot enhanced metrics for summarization models.\"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "    # Length\n",
        "    ax1.bar(['T5', 'BART', 'PEGASUS'],\n",
        "            [metrics['t5']['length'], metrics['bart']['length'], metrics['pegasus']['length']],\n",
        "            color='gold')\n",
        "    ax1.set_title('Summary Length')\n",
        "\n",
        "    # Similarity to Original\n",
        "    ax2.bar(['T5', 'BART', 'PEGASUS'],\n",
        "            [metrics['t5']['sim_to_original'],\n",
        "             metrics['bart']['sim_to_original'],\n",
        "             metrics['pegasus']['sim_to_original']],\n",
        "            color='lightcoral')\n",
        "    ax2.set_title('Similarity to Original')\n",
        "\n",
        "    plt.suptitle(title, fontsize=14)\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "plot_enhanced_summarization_comparison(comparison_first, title=\"Summarization Comparison (Alice’s Adventures in Wonderland)\")\n",
        "plot_enhanced_summarization_comparison(comparison_second, title=\"Summarization Comparison (The Adventures of Sherlock Holmes)\")"
      ],
      "metadata": {
        "id": "2KqCniz5lxLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 6.2: Enhanced Paraphrasing Metrics Plot\n",
        "Visualize PEGASUS vs T5-Paraphrase vs BART-Paraphrase metrics."
      ],
      "metadata": {
        "id": "eT4p46Tclyle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_enhanced_paraphrasing_comparison(metrics, title=\"Paraphrasing Comparison\"):\n",
        "    \"\"\"Plot enhanced metrics for paraphrasing models.\"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "    # Average Length\n",
        "    ax1.bar(['PEGASUS', 'T5-Paraphrase', 'BART-Paraphrase'],\n",
        "            [metrics['pegasus']['avg_length'],\n",
        "             metrics['t5_paraphrase']['avg_length'],\n",
        "             metrics['bart_paraphrase']['avg_length']],\n",
        "            color='gold')\n",
        "    ax1.set_title('Average Paraphrase Length')\n",
        "\n",
        "    # Average Similarity to Original\n",
        "    ax2.bar(['PEGASUS', 'T5-Paraphrase', 'BART-Paraphrase'],\n",
        "            [metrics['pegasus']['avg_sim_to_original'],\n",
        "             metrics['t5_paraphrase']['avg_sim_to_original'],\n",
        "             metrics['bart_paraphrase']['avg_sim_to_original']],\n",
        "            color='lightcoral')\n",
        "    ax2.set_title('Average Similarity to Original')\n",
        "\n",
        "    plt.suptitle(title, fontsize=14)\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "# Plot paraphrasing comparison for first sentence of first text\n",
        "first_sentence = re.split(r'[.!?]+', first_text)[0].strip()\n",
        "plot_enhanced_paraphrasing_comparison(compare_paraphrasers_enhanced(first_sentence),\n",
        "                                     title=\"Paraphrasing Comparison (Alice’s Adventures in Wonderland Sentence)\")"
      ],
      "metadata": {
        "id": "uWY51Utyl1WP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 6.3: Bigram Analysis\n",
        "Add bigram analysis using simple string splitting."
      ],
      "metadata": {
        "id": "Z4urzFrQpiHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_bigrams(text):\n",
        "    \"\"\"Compute top bigrams using string splitting.\"\"\"\n",
        "    text = clean_text(text[:2000])  # Clean and limit for performance\n",
        "    words = text.split()\n",
        "    bigrams = [(words[i], words[i+1]) for i in range(len(words)-1)]\n",
        "    bigram_freq = Counter(bigrams).most_common(5)\n",
        "    return [(f\"{w1} {w2}\", count) for (w1, w2), count in bigram_freq]\n",
        "\n",
        "print(\"\\nBigram Analysis\")\n",
        "for key, data in loaded_texts.items():\n",
        "    print(f\"\\n{key}:\")\n",
        "    bigrams = analyze_bigrams(data['text'])\n",
        "    print(f\"Top Bigrams: {bigrams}\")"
      ],
      "metadata": {
        "id": "-T4OFs2Mpqwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 6.4: Bigram Visualization\n",
        "Visualize bigram frequencies."
      ],
      "metadata": {
        "id": "5QXXOjoQp0xR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_bigrams(bigrams, title=\"Top Bigrams\"):\n",
        "    \"\"\"Plot top bigrams.\"\"\"\n",
        "    if bigrams:\n",
        "        labels, counts = zip(*bigrams)\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        plt.bar(labels, counts, color='teal')\n",
        "        plt.title(title, fontsize=12)\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "for key, data in loaded_texts.items():\n",
        "    bigrams = analyze_bigrams(data['text'])\n",
        "    plot_bigrams(bigrams, title=f\"Top Bigrams ({key})\")"
      ],
      "metadata": {
        "id": "NGEa2XdHp4MY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 6.5: Word Cloud Visualization\n",
        "Shows the most frequent words in the text."
      ],
      "metadata": {
        "id": "NRhvr_BTWr-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install wordcloud if not already\n",
        "!pip install wordcloud --quiet\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "def plot_wordcloud(text, title=\"Word Cloud\"):\n",
        "    \"\"\"Generate and plot a word cloud from text.\"\"\"\n",
        "    text = clean_text(text)\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white',\n",
        "                          colormap='viridis', max_words=150).generate(text)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "for key, data in loaded_texts.items():\n",
        "    plot_wordcloud(data['text'], title=f\"Word Cloud ({key})\")\n"
      ],
      "metadata": {
        "id": "KamspcahUEoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 6.6: Heatmap Visualization\n",
        "Displays word co-occurrence frequencies across the text."
      ],
      "metadata": {
        "id": "wsVMp8HTW-Fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "def plot_bigram_heatmap(text, top_n=10, title=\"Bigram Heatmap\"):\n",
        "    \"\"\"Create a heatmap for top bigrams.\"\"\"\n",
        "    text = clean_text(text[:5000])  # Limit to first 5000 chars for speed\n",
        "    words = text.split()\n",
        "    bigrams = [(words[i], words[i+1]) for i in range(len(words)-1)]\n",
        "    bigram_freq = Counter(bigrams).most_common(top_n)\n",
        "\n",
        "    # Convert to DataFrame for heatmap\n",
        "    df = pd.DataFrame(bigram_freq, columns=['Bigram', 'Frequency'])\n",
        "    bigram_labels = [' '.join(b) for b in df['Bigram']]\n",
        "    heatmap_data = pd.DataFrame({'Bigram': bigram_labels, 'Frequency': df['Frequency']})\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.heatmap(heatmap_data.set_index('Bigram').T, annot=True, cmap='YlGnBu', cbar=True)\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "for key, data in loaded_texts.items():\n",
        "    plot_bigram_heatmap(data['text'], top_n=10, title=f\"Top 10 Bigrams Heatmap ({key})\")\n"
      ],
      "metadata": {
        "id": "K82S8JJKVZ02"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
